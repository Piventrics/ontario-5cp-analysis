{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IESO Zonal Demand Data Downloader\n",
        "\n",
        "This notebook downloads zonal demand data from the IESO public reports website.\n",
        "\n",
        "## Data Source\n",
        "Source: [IESO Zonal Demand Reports](https://reports-public.ieso.ca/public/DemandZonal/)\n",
        "\n",
        "## What is Zonal Demand Data?\n",
        "Zonal demand data shows electricity demand broken down by different zones/regions in Ontario. This is useful for:\n",
        "- Understanding regional electricity consumption patterns\n",
        "- Analyzing demand distribution across Ontario\n",
        "- Regional capacity planning\n",
        "- Comparing demand patterns between different zones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üì¶ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup directories\n",
        "data_dir = Path(\"data/raw/zonal_demand\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Data directory: {data_dir}\")\n",
        "print(f\"‚úÖ Directory created/verified\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define files to download\n",
        "base_url = \"https://reports-public.ieso.ca/public/DemandZonal/\"\n",
        "\n",
        "# List of zonal demand files (based on IESO directory listing)\n",
        "files_to_download = [\n",
        "    \"PUB_DemandZonal.csv\",  # Current year (2025)\n",
        "    \"PUB_DemandZonal_2024.csv\",\n",
        "    \"PUB_DemandZonal_2023.csv\", \n",
        "    \"PUB_DemandZonal_2022.csv\",\n",
        "    \"PUB_DemandZonal_2021.csv\",\n",
        "    \"PUB_DemandZonal_2020.csv\",\n",
        "    \"PUB_DemandZonal_2019.csv\",\n",
        "    \"PUB_DemandZonal_2018.csv\",\n",
        "    \"PUB_DemandZonal_2017.csv\",\n",
        "    \"PUB_DemandZonal_2016.csv\",\n",
        "    \"PUB_DemandZonal_2015.csv\",\n",
        "    \"PUB_DemandZonal_2014.csv\",\n",
        "    \"PUB_DemandZonal_2013.csv\",\n",
        "    \"PUB_DemandZonal_2012.csv\",\n",
        "    \"PUB_DemandZonal_2011.csv\",\n",
        "    \"PUB_DemandZonal_2010.csv\",\n",
        "    \"PUB_DemandZonal_2009.csv\",\n",
        "    \"PUB_DemandZonal_2008.csv\",\n",
        "    \"PUB_DemandZonal_2007.csv\",\n",
        "    \"PUB_DemandZonal_2006.csv\",\n",
        "    \"PUB_DemandZonal_2005.csv\",\n",
        "    \"PUB_DemandZonal_2004.csv\",\n",
        "    \"PUB_DemandZonal_2003.csv\"\n",
        "]\n",
        "\n",
        "print(f\"üìã {len(files_to_download)} files to download\")\n",
        "print(f\"üåê Base URL: {base_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download function\n",
        "def download_file(filename, url, local_path):\n",
        "    \"\"\"Download a single file\"\"\"\n",
        "    try:\n",
        "        print(f\"üì• Downloading {filename}...\")\n",
        "        \n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        # Save file\n",
        "        with open(local_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        \n",
        "        file_size = local_path.stat().st_size\n",
        "        print(f\"‚úÖ Downloaded {filename} ({file_size / 1024 / 1024:.1f} MB)\")\n",
        "        return True, file_size\n",
        "        \n",
        "    except requests.RequestException as e:\n",
        "        print(f\"‚ùå Failed to download {filename}: {e}\")\n",
        "        return False, 0\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error with {filename}: {e}\")\n",
        "        return False, 0\n",
        "\n",
        "print(\"üîß Download function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download all files\n",
        "print(\"üöÄ Starting download process...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "successful_downloads = 0\n",
        "total_size = 0\n",
        "failed_files = []\n",
        "\n",
        "for filename in files_to_download:\n",
        "    url = base_url + filename\n",
        "    local_path = data_dir / filename\n",
        "    \n",
        "    # Skip if file already exists\n",
        "    if local_path.exists():\n",
        "        print(f\"‚è≠Ô∏è  Skipping {filename} (already exists)\")\n",
        "        successful_downloads += 1\n",
        "        total_size += local_path.stat().st_size\n",
        "        continue\n",
        "    \n",
        "    success, file_size = download_file(filename, url, local_path)\n",
        "    \n",
        "    if success:\n",
        "        successful_downloads += 1\n",
        "        total_size += file_size\n",
        "    else:\n",
        "        failed_files.append(filename)\n",
        "    \n",
        "    # Be respectful to IESO servers\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(f\"\\nüìä DOWNLOAD SUMMARY:\")\n",
        "print(f\"   ‚Ä¢ Files downloaded: {successful_downloads}/{len(files_to_download)}\")\n",
        "print(f\"   ‚Ä¢ Total data size: {total_size / 1024 / 1024:.1f} MB\")\n",
        "print(f\"   ‚Ä¢ Data location: {data_dir}\")\n",
        "\n",
        "if failed_files:\n",
        "    print(f\"   ‚Ä¢ Failed files: {failed_files}\")\n",
        "\n",
        "if successful_downloads > 0:\n",
        "    print(f\"\\n‚úÖ Download completed successfully!\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå No files were downloaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify downloaded files\n",
        "print(\"üîç Verifying downloaded files...\")\n",
        "\n",
        "csv_files = list(data_dir.glob(\"*.csv\"))\n",
        "print(f\"üìÅ Found {len(csv_files)} CSV files in {data_dir}\")\n",
        "\n",
        "for file_path in csv_files:\n",
        "    file_size = file_path.stat().st_size\n",
        "    print(f\"   ‚Ä¢ {file_path.name}: {file_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "if csv_files:\n",
        "    print(f\"\\n‚úÖ Verification complete - {len(csv_files)} files ready for analysis\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå No CSV files found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample data preview (optional)\n",
        "if csv_files:\n",
        "    # Load the most recent file as a sample\n",
        "    sample_file = csv_files[0]  # Assuming they're sorted by name\n",
        "    \n",
        "    try:\n",
        "        print(f\"üìä Sample data from {sample_file.name}:\")\n",
        "        sample_data = pd.read_csv(sample_file, nrows=5)\n",
        "        print(sample_data.head())\n",
        "        print(f\"\\nüìã Columns: {list(sample_data.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not preview data: {e}\")\n",
        "else:\n",
        "    print(\"No files available for preview\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have downloaded the zonal demand data, you can:\n",
        "\n",
        "1. **Analyze the data structure** - Examine the columns and data format\n",
        "2. **Combine multiple years** - Merge data from different years for trend analysis\n",
        "3. **Regional analysis** - Compare demand patterns across different zones\n",
        "4. **Time series analysis** - Look at hourly, daily, and seasonal patterns\n",
        "5. **Integration with 5CP analysis** - Use this data alongside your existing 5CP analysis\n",
        "\n",
        "## Data Description\n",
        "\n",
        "The zonal demand data typically includes:\n",
        "- **Date/Time**: Hourly timestamps\n",
        "- **Zone columns**: Different regions/zones in Ontario\n",
        "- **Total demand**: Sum of all zones\n",
        "- **Individual zone demands**: Breakdown by region\n",
        "\n",
        "This data complements your existing 5CP analysis by providing regional granularity.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
